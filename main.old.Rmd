---
title: "Maven Central Analysis: overview "
output:
  html_document:
    df_print: paged
---
In this R Notebook, we list the required steps top reproduce the analysis performed on the Maven dependency graph collected using [Maven-miner](https://github.com/diverse-project/maven-miner) project.
The graph database together the results of our analysis queries will be provided very soon.

In case the required packages are installed, you can skip the next code section.
# Installing missing packages

```{r}
if("dplyr" %in% rownames(installed.packages()) == FALSE) { install.packages("dplyr") }

#install.packages("dplyr", dependencies = TRUE)
#install.packages("tidyverse", dependencies=TRUE)
#install.packages("stringr", dependencies=TRUE)
#install.packages("igraph", dependencies=TRUE)
#install.packages("poweRlaw", dependencies=TRUE)
#install.packages("wesanderson", dependencies=TRUE)
#install.packages("xtable", dependencies=TRUE)
```
We first start by loading the required packages. Later we read the data from CSV.

# Loading packages
```{r}

library(tidyr)
library(dplyr)
library(stringr)
library(igraph)
library(poweRlaw)
library(wesanderson)
library(xtable)
library(ggplot2)
theme_set(theme_bw())

```

# Data Prepation
If you are not interested in reconstructing 
In this section, we give a brief explanation of the data files content, and describe the Cypher queries  we used to extract data.

:warning: Before kicking off, we need to set up the path where the downloaded data is located. To do so, in the following snippet, replace variable **$path** with the actual path. For instance *path =/home/user/maven-miner-data*.

```{r}
path = "/home/amine/maven-miner-stat"
```  

##  Artifacts release dates

The file *release_all.csv* contains all the artifacts and their corresponding release date. Artifacts are identified using the GAV representation (Group:Artifact:Version).
The Release dates come in the formats **AAAA-MM-DD HH:MM:SS [ZZZ]**.

We use the following Cypher query to retrieve the data: 

```
CALL apoc.export.csv.query("MATCH (artifact:Artifact) RETURN artifact.coordinates as artifact, artifact.release_date as release", "/path/to/release_all.csv", {})
```

```{r}
# artifact |  release
release_all_path <- paste(path, "release_all.csv", sep="/")
release_all <- read.csv(release_all_path)
```  

##  Page rank algorithm

The file *pagerank_all.csv* contains the page rank score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to compute the page-rank algorithm

```
CALL apoc.export.csv.query("CALL algo.pageRank.stream('Artifact', 'DEPENDS_ON', {iterations:10, dampingFactor:0.85}) YIELD nodeId, score MATCH (node) WHERE id(node) = nodeId RETURN node.coordinates AS artifact, score AS page_rank ORDER BY score DESC", "/path/to/pagerank_all.csv", {});
```

```{r}
# // artifact | page_rank

page_rank_path <-  paste(path,"pagerank_all.csv",sep="/")
page_rank <- read.csv(page_rank_path)
```
##  Louvain algorithm
The file *louvain_all.csv* contains the page Louvain score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to compute the Louvain algorithm

```
CALL apoc.export.csv.query("CALL algo.louvain.stream('Artifact', 'DEPENDS_ON', {}) YIELD nodeId, community MATCH (node) WHERE id(node) = nodeId RETURN node.coordinates AS artifact, community", "/path/to/louvain_all.csv", {});
```

```{r}
# // artifact | community

louvain_all_path <- paste(path, "louvain_all.csv", sep="/")
louvain <- read.csv(louvain_all_path)

```
##  Centrality algorithm
### Betweeness centrality
The file *betweenness_centrality.csv* contains the page centrality score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to run the Betweeness centrality algorithm:

```
CALL apoc.export.csv.query("CALL algo.betweenness.stream('Artifact','DEPENDS_ON',{direction:'out'}) YIELD nodeId, centrality MATCH (user:Artifact) WHERE id(user) = nodeId RETURN user.coordinates AS artifact, centrality AS betweenness_centrality ORDER BY centrality DESC","/path/to/betweenness_centrality_all.csv", {});
```

```{r}
# // artifact | centrality
betweenness_centrality_all_path <- paste(path,"betweenness_centrality_all.csv", sep="/")
betweenness_centrality <- read.csv(betweenness_centrality_all_path)
```
### Harmonic centrality
The file *harmonic_centrality.csv* contains the page centrality score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to run the Harmonic centrality algorithm:

```
CALL apoc.export.csv.query("CALL algo.closeness.harmonic.stream('Artifact', 'DEPENDS_ON') YIELD nodeId, centrality MATCH (node) WHERE id(node) = nodeId RETURN node.coordinates as artifact, centrality AS harmonic_centrality ORDER BY centrality DESC","%PATH%/harmonic_centrality_all.csv", {});
```
```{r}
# // artifact | harmonic_centrality
harmonic_centrality_all_path <- paste(path, "harmonic_centrality_all.csv", sep="/")
harmonic_centrality <- read.csv(harmonic_centrality_all_path)
```
### Label propagation algorithm
The file *label_propagation.csv* contains the page label propagation score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to run the label propagation algorithm:

```
CALL apoc.export.csv.query("CALL algo.labelPropagation.stream('Artifact', 'DEPENDS_ON', {direction: 'OUTGOING', iterations: 10}) YIELD nodeId, label MATCH (node) WHERE id(node) = nodeId RETURN node.coordinates as artifact, label","/path/to/label_propagation.csv", {});
```
```{r}
# // artifact | label
label_propagation_path <- paste(path, "label_propagation.csv", sep = "/")
label_propagation <- read.csv(label_propagation_path)
```
### Union find algorithm
The file *union_find.csv* contains the page Louvain score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to run the union find algorithm:

```
CALL apoc.export.csv.query("CALL algo.unionFind.stream('Artifact', 'DEPENDS_ON', {}) YIELD nodeId, setId MATCH (artifact:Artifact) WHERE id(artifact) = nodeId RETURN artifact.coordinates AS artifact, setId AS union_find","%PATH%/union_find.csv", {});
```
```{r}
# // artifact | union_find
union_find_path <- paste(path, "union_find.csv", sep = "/")
union_find <- read.csv(union_find_path)
```
### Artifacts Direct usages count  
The file *direct_usages.csv* contains, for every artifact, the number of artifacts using it. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to run the Betweeness centrality algorithm:

```
CALL apoc.export.csv.query("MATCH (n:Artifact) RETURN n.coordinates AS artifact, size((n)<-[:DEPENDS_ON]-()) as direct_usages ORDER BY direct_usages DESC","%PATH%/direct_usages.csv", {});
```
```{r}
# // artifact | direct_usages
direct_usages_path <- paste(path, "direct_usages.csv", sep = "/")
direct_usages <- read.csv(direct_usages_path)
```
### Artifacts Direct dependency count  
The file *direct_dependencies.csv* contains the number of dependencies of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to retrieve dependency count:

```
CALL apoc.export.csv.query("MATCH (n:Artifact) RETURN n.coordinates AS artifact, size((n)-[:DEPENDS_ON]->()) as direct_dependencies ORDER BY direct_dependencies DESC","%PATH%/direct_dependencies.csv", {});
```

```{r}
# // artifact | direct_dependencies
direct_dependencies_path <- paste(path, "direct_dependencies.csv", sep = "/")
direct_dependencies <- read.csv(direct_dependencies_path)
```

### Artifacts transitive usages count 

The file *transitive_usages.csv* contains the page Louvain score of every artifact. 
Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to retrieve the transitive usage count:

```
CALL apoc.export.csv.query("match (n)<-[r:DEPENDS_ON*]-(m) where (m)<-[:DEPENDS]-() return n.coordinates as artifact, count(distinct m) as transitive_usages","/path/to/trans_usages_all.csv", {});
```
```{r}
# // artifact | 
trans_usages_path <- paste(path, "direct_dependencies.csv", sep = "/")
trans_usages <- read.csv(trans_usages_path)
colnames(trans_usages) <- c("artifact", "trans_usages")

```

## Data processing & cleaning

We first join all the CSV files into a the same data frame
```{r}
# merge the data
a <- dplyr::full_join(page_rank, louvain, by = "artifact")
b <- dplyr::full_join(a, betweenness_centrality, by = "artifact")
c <- dplyr::full_join(b, harmonic_centrality, by = "artifact")
d <- dplyr::full_join(c, label_propagation, by = "artifact")
e <- dplyr::full_join(d, direct_usages, by = "artifact")
f <- dplyr::full_join(e, union_find, by = "artifact")
g <- dplyr::full_join(f, trans_usages, by = "artifact")
h <- dplyr::full_join(g, direct_dependencies, by = "artifact")
i <- dplyr::full_join(h, release_all, by = "artifact")
```

Later, we clean the data by replacing all NA values by Zero (0)
```{r}
# replace NAs
i$direct_usages <- i$direct_usages %>% replace_na(0)
i$trans_usages <- i$trans_usages %>% replace_na(0)
i$direct_dependencies <- i$direct_dependencies %>% replace_na(0)
```


```{r}
final_join <- i

# split artifact into GroupId, ArtifactId and Version
data <- cbind(as.data.frame(stringr::str_split_fixed(final_join$artifact, ":", 3)),
              final_join$page_rank,
              final_join$community,
              final_join$betweenness_centrality,
              final_join$harmonic_centrality,
              final_join$label,
              final_join$direct_usages,
              final_join$union_find,
              final_join$trans_usages,
              final_join$direct_dependencies,
              final_join$release
              )
```

Splitting GAV into separate columns, groupID, artifactID, and version. Then we rename the columns 
```{r}
# type cast release to Date
data$`final_join$release` <- as.Date(format(as.Date(str_sub(data$`final_join$release`, 1, 10)),'%Y-%m-%d'), '%Y-%m-%d')

# rename columns
data <- data %>% dplyr::rename(
  GroupId = V1,
  ArtifactId = V2,
  Version = V3,
  Release = `final_join$release`,
  PageRank = `final_join$page_rank`,
  Dependencies = `final_join$direct_dependencies`,
  DUsages = `final_join$direct_usages`,
  TUsages = `final_join$trans_usages`,
  Louvain = `final_join$community`,
  BetwCentrality = `final_join$betweenness_centrality`,
  HarmCentrality = `final_join$harmonic_centrality`,
  UnionFind = `final_join$union_find`,
  LabelProp = `final_join$label`
  )

# cluster variables to factors
data$UnionFind <- as.factor(data$UnionFind )
summary(data$UnionFind)
```

```{r}

# see the data
View(data)
dim(data)
```

```{r}
#write to a CSV 2407336
# path = "/home/amine/maven-miner-stat"
# write.csv(data, file = "/home/amine/maven-miner-stat/allMetrics.csv")
```

# Directly reading the final dataset

In case you skipped the data preparation phase. This section is for you. 
You can read the final dataset directly using the following R chunk:
```{r}
# data <- read.csv("/home/amine/maven-miner-stat/allMetrics.csv")
```

##  All dependency links
The file *links_all.csv* contains all the dependecy relationships (source -> target).  Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to list all the dependecy links:

```
CALL apoc.export.csv.query("MATCH (n:Artifact)-[:DEPENDS_ON]->(m:Artifact) RETURN n.coordinates AS source, m.coordinates AS target", "/path/to/links_all.csv", {});
```

```{r}
# // source | target
links_all_path <- paste(path,"links_all.csv",sep="/")
links_all <- read.csv(links_all_path)
``` 
##  All upgrade links
The file *next_all.csv* contains all the upgrade relationships (source -> target).  Artifacts are identified using the GAV representation (Group:Artifact:Version).

We use the following Cypher query to list all the dependecy links:

```
CALL apoc.export.csv.query("MATCH (n:Artifact)-[:NEXT]->(m:Artifact) RETURN n.coordinates AS source, m.coordinates AS target", "/path/to/next_all.csv", {});
```


```{r}
# // source | target
next_all_path <- paste(path,"next_all.csv",sep="/")
next_all <- read.csv(next_all_path)
```  

# Data visualization
Hereafter, we depict some plots about different aspects of the dependency graph (maven central evolution, dependencies & usages counts, etc.).

## General overview


```{r}
nodes_count <- dim(data)[1]
edges_count <-dim(links_all)[1]
upgrades_count <- dim(next_all)[1]
cat ("The graph contains", nodes_count, "artifacts and", edges_count, "dependency relationship, and", upgrades_count, "upgrades!" )
cat ("\nMoreover, the graph contains 35,699 unique groupIds and 223,478 unique groupId:artifactId")

#adding information about the number of upgrades 

```

```{r}

data %>% ggplot(aes(Release)) +
  geom_density() +
  xlab("Release date")

```
```{r}
# peek 2016-08-10 531020
table_release <- data %>% select(ArtifactId,Release) %>% arrange(Release) %>% group_by(Release) %>% summarise(count=n()) %>% mutate(sum = cumsum(count)) 
table_release %>%ggplot(aes(x = Release, y = sum))+
  geom_line() +
  xlab("Release date") +
  ylab("Artifacts count")

```

```{r}
#names(table(data$DUsages))
#print(cumsum(1:10))
```

# Degree distribution
In this section, we introduce in a nutshell the maven dependency graph anatomy.


## out-degree distribution

Before investigating artifacts dependencies, let's first take a look at a quick overview of the different quantile values:

```{r}
G.out.degree.mean <- mean(data$Dependencies, na.rm=T)
G.out.degree.quantiles <- quantile(data$Dependencies, c(.5,.99, .999))
G.out.degree.min <- min(data$Dependencies)
G.out.degree.max <- max(data$Dependencies)
cat ("The mean, median, .99th quantile, and .999th quantile od dependencies per artifact are respectively", G.out.degree.mean, G.out.degree.quantiles[1], G.out.degree.quantiles[2], G.out.degree.quantiles[3], sep = ", ")

cat("\nThe min and max are respectively", G.out.degree.min, G.out.degree.max)

G.out.frame <- as.data.frame(data$Dependencies)
g.out.degree.zero <- colSums(G.out.frame==0)
g.out.degree.one <- colSums(G.out.frame==1)

cat ("\nThere number of elements with no dependencies and only one dependency are respectively", g.out.degree.zero, g.out.degree.one, sep = ", ")
```

```{r}

# ggplot(G.out.frame, aes(x=data$Dependencies))+
#     geom_histogram(binwidth=.2, colour="black", fill="white") +
#     xlab("Dependencies")+
#     geom_vline(aes(xintercept=G.out.degree.quantiles[1]),   # Ignore NA values for mean
#                color="red", linetype="dashed", size=1) +
#     geom_vline(aes(xintercept=G.out.degree.quantiles[2]),   # 
#                color="blue", linetype="dashed", size=1) +
#     geom_vline(aes(xintercept=G.out.degree.quantiles[3]),   # 
#                color="green", linetype="dashed", size=1) +
#     # scale_x_continuous("Artifacts", trans = "log10") +
#     scale_y_continuous("Artifacts", trans = "log10" )


G.out.degrees <- data$Dependencies    
# Let's count the frequencies of each degree
G.out.degree.histogram <- as.data.frame(table(G.out.degrees))

# Need to convert the first column to numbers, otherwise
# the log-log thing will not work (that's fair...)
G.out.degree.histogram[,1] <- as.numeric(G.out.degree.histogram[,1])

# Now, plot it!
ggplot(G.out.degree.histogram, aes(x = G.out.degrees, y = Freq)) +
  # geom_step() +
  geom_line() +
  # artifacts with this number of dependencies
  scale_x_continuous("Dependencies (Out-degree)",
                     trans = "log10") +
  # how many of them
  scale_y_continuous("Artifacts count",
                     trans = "log10")

```
This graph shows a histogram of dependencies count. As we can notice, almost 1M artifacts have at most one dependency. Indeed, 641463 artifact do not have any dependency. These artifacts are mostly already shipped with their classpath.  They rely on Maven only for deploying the artifacts on the repository, but not for dependency management. Surprisingly, 71% of top 100 popular artifacts do not have any dependency. 6% more have only one dependency. Finally, 960 artifacts have more than 100 dependency. Whilst, most of the depedency with only one dependency use other artifacts belonging to the same group, sometimes even the same release. The later upgrade altogether at once. We suspect them to be different modules belonging to the same maven project.
```{r}
occur = as.vector(table(data$Dependencies))
occur = occur/sum(occur)
p = occur/sum(occur)
y = rev(cumsum(rev(p)))
x = as.numeric(names(table(data$Dependencies)))


plot(x, y, log="y", type="l", xlab = "Dependencies (Out-degree)", ylab = "Fraction")
abline(v=G.out.degree.quantiles[1], col="red")
abline(v=G.out.degree.quantiles[2], col="blue")
abline(v=G.out.degree.quantiles[3], col="green", )
#occur = as.vector(table(data$TUsages))
#occur = occur/sum(occur)
#p = occur/sum(occur)
#y = rev(cumsum(rev(p)))
#x = as.numeric(names(table(data$TUsages)))
#plot(x, y, log="y", type="l", xlab = "Degree", ylab = "Fraction")

```
This plot simply shows the percentage of artifacts (y) having a certain number (x) of dependencies. As we can notice, as the number of dependencies increases, the percentage of artifacts decreases.

## in-degree distribution
In this section we investigate the dependecies uage.
A quick overview of the different quantiles of dependencies usage counts is depicted below:
```{r}
G.in.degree.mean <- mean(data$DUsages, na.rm=T)
G.in.degree.quantiles <- quantile(data$DUsages, c(.5,.99, .999))
G.in.degree.min <- min(data$DUsages)
G.in.degree.max <- max(data$DUsages)
cat ("The mean, median, .99th quantile, and .999th quantile of usages per artifact node are respectively ", G.in.degree.mean, G.in.degree.quantiles[1], G.in.degree.quantiles[2], G.in.degree.quantiles[3], sep = ", " )

cat("\nThe min and max are respectively", G.in.degree.min, G.in.degree.max)

G.in.frame <- as.data.frame(data$DUsages)
g.in.degree.zero <- colSums(G.in.frame==0)
g.in.degree.one <- colSums(G.in.frame==1)

cat ("\nThere number of elements with no usages and only one usage are respectively", g.in.degree.zero, g.in.degree.one, sep = ", ")
```

```{r}

# ggplot(G.in.frame, aes(x=data$DUsages))+
#     geom_histogram(binwidth=.2, colour="black", fill="white") +
#     xlab("Usages")+
#     geom_vline(aes(xintercept=G.in.degree.quantiles[1]),   # Ignore NA values for mean
#                color="red", linetype="dashed", size=1) +
#     geom_vline(aes(xintercept=G.in.degree.quantiles[2]),   # 
#                color="blue", linetype="dashed", size=1) +
#     geom_vline(aes(xintercept=G.in.degree.quantiles[3]),   # 
#                color="green", linetype="dashed", size=1) +
#     # scale_x_continuous("Artifacts", trans = "log10") +
#     scale_y_continuous("Artifacts", trans = "log10" )

```

```{r}
G.in.degrees <- data$DUsages
# Let's count the frequencies of each degree
G.in.degree.histogram <- as.data.frame(table(G.in.degrees))

# Need to convert the first column to numbers, otherwise
# the log-log thing will not work (that's fair...)
G.in.degree.histogram[,1] <- as.numeric(G.in.degree.histogram[,1])
# Now, plot it!
ggplot(G.in.degree.histogram, aes(x = G.in.degrees, y = Freq)) +
  # geom_step() +
  geom_line() +
  # artifacts with this number of dependencies
  scale_x_continuous("Usages",
                     trans = "log10") +
  # how many of them
  scale_y_continuous("Frequency",
                     trans = "log10")
```
This graph shows the frequency usage of Maven central artifacts. As we can notice, more than 1.8M elements with at most one usage. Actually, almost 56% (1335418) of the  artifacts have been never used by other artifacts. 20% (499363) more have been used only once. Similarly to the dependencies count, most of these artifacts are used by other artifacts belonging to the same group and same release. The later upgrade altogether at once. We also suspect them to be different modules belonging to the same Maven project.


```{r}
occur = as.vector(table(data$DUsages))
occur = occur/sum(occur)
p = occur/sum(occur)
y = rev(cumsum(rev(p)))
x = as.numeric(names(table(data$DUsages)))
plot(x, y, log="y", type="l", xlab = "Usages", ylab = "Population fraction")
abline(v=G.in.degree.quantiles[1], col="red")
abline(v=G.in.degree.quantiles[2], col="blue")
abline(v=G.in.degree.quantiles[3], col="green")
#occur = as.vector(table(data$TUsages))
#occur = occur/sum(occur)
#p = occur/sum(occur)
#y = rev(cumsum(rev(p)))
#x = as.numeric(names(table(data$TUsages)))
#plot(x, y, log="y", type="l", xlab = "Degree", ylab = "Fraction")

```

```{r}

# Page Rank Table
table_pagerank <- data %>% select(GroupId, ArtifactId, Version, Dependencies, DUsages, TUsages, PageRank) %>% slice(1:10)
print(xtable(table_pagerank, type = "latex"), file = "TexTables/table_pagerank.tex")
# # Betweenness Centrality Table
# table_betw_path <- paste(path, "TexTables/table_betw.tex", sep="/")
# table_betw <- data %>% select(GroupId, ArtifactId, Version, Dependencies, DUsages, TUsages, BetwCentrality) %>% arrange(desc(BetwCentrality)) %>% slice(1:10)
# print(xtable(table_betw, type = "latex"), file = table_betw_path)
# # Harmonic Centrality Table
# table_harm_path <- paste(path,"TexTables/table_harm.tex",sep = "/" )
# table_harm <- data %>% select(GroupId, ArtifactId, Version, Dependencies, DUsages, TUsages, HarmCentrality) %>% arrange(desc(HarmCentrality)) %>% slice(1:10)
# print(xtable(table_harm, type = "latex"), file = table_harm_path)

```
# Projects' usage
The following figures show the top 10 most used projects both directly and transitively.
We use the PageRank algorithm score to quantify the popularity. This score can be regarded as a proxy to the transitive usage count of artifacts. 



```{r}

datatmp <- data %>%
  mutate(Coordinates = paste(as.character(GroupId), as.character(ArtifactId), as.character(Version), sep=":")) %>%
  arrange(desc(PageRank)) %>%
  select(Coordinates, PageRank)%>%
  slice(1:10)

datatmp$Coordinates <- factor(datatmp$Coordinates, levels = datatmp$Coordinates[order(datatmp$PageRank)])
datatmp %>%
  ggplot(aes(x=Coordinates, y=PageRank)) +
  geom_point(size=3) +
  geom_segment(aes(x=Coordinates,
                   xend=Coordinates,
                   y=0,
                   yend=PageRank)) +
  coord_flip() +
    ylab("PageRank") +
  xlab("")
```


```{r}
datatmp <- data %>%
  mutate(Coordinates = paste(as.character(GroupId), as.character(ArtifactId), as.character(Version), sep=":")) %>%
  arrange(desc(DUsages)) %>%
  select(Coordinates, DUsages)%>%
  slice(1:10)

datatmp$Coordinates <- factor(datatmp$Coordinates, levels = datatmp$Coordinates[order(datatmp$DUsages)])
datatmp %>%
  ggplot(aes(x=Coordinates, y=DUsages)) +
  geom_point(size=3) +
  geom_segment(aes(x=Coordinates,
                   xend=Coordinates,
                   y=0,
                   yend=DUsages)) +
  coord_flip() +
  ylab("Direct Usages") +
  xlab("")

```
# Projects' evolution
The following plot shows the per-version popularity evolution of the top 5 most used artifacts in maven:
```{r}
max <- max(data$PageRank)
top5 <- c("org.slf4j", "commons-lang", "commons-io" ,"commons-logging", "org.scala-lang")
#top5 <- data %>% select(GroupId, DUsages) %>% top_n(5,DUsages) %>%select(GroupId)
data %>%
  select(GroupId, Release, PageRank, Version) %>%
  filter(GroupId %in% top5 ) %>%
  group_by(GroupId) %>%
  top_n(10, PageRank)%>%
  mutate(factor = PageRank/max)%>%
  ggplot(aes(Release, factor, color = GroupId, shape = GroupId)) +
  geom_line() +
  geom_point(size = 2) +
  geom_text(aes(label=ifelse(factor>.2,as.character(Version),'')),hjust=0,vjust=0,show.legend = FALSE) +
  xlab("Release Date") +
  ylab("PageRank factor") +
  theme(legend.position="top")+
  scale_fill_manual(values=wes_palette(n=3, name="GrandBudapest1"))

```

The following plot shows the usage evolution of the top 5 most influencing in Maven.
As we can notice, apart from the '**org.slf4j**', the most influencing versions per artifacts are intermediate past versions.
We normalized the PageRank score on a scale of 0 to 1., with zero being the less influencing and 1 the most influencing.
We also notice that the artifacts with the most influence minor version releases. 
We can conclude that providing new releases does not result in particular in a chain of upgrades from the transitive users side.
```{r}

top5 <- c("com.google.code.findbugs ", "org.scala-lang", "org.slf4j" ,"javax.inject", "log4j")
#top5 <- data %>% select(GroupId, DUsages) %>% top_n(5,DUsages) %>%select(GroupId)
data %>%
  select(GroupId, Release, DUsages, Version) %>%
  filter(GroupId %in% top5 ) %>%
  group_by(GroupId) %>%
  top_n(10, DUsages)%>%
  mutate(factor = DUsages)%>%
  ggplot(aes(Release, factor, color = GroupId, shape = GroupId)) +
  geom_line() +
  geom_point(size = 2) +
  geom_text(aes(label=ifelse(factor>5000,as.character(Version),'')),hjust=0,vjust=0,show.legend = FALSE) +
  xlab("Release Date") +
  #scale_y_continuous("Direct Usages", trans = "log10")+
  theme(legend.position="top")+
  scale_fill_manual(values=wes_palette(n=3, name="GrandBudapest1"))

```
On the contrary to the previous plot, this one shows the evolution of direct usages of top 5 most inflential artifacts.
We can notice that direct usage and transitive usages has, more or less, the same evolution trends 


```{r}
# data %>%
#   select(GroupId, Release, PageRank, Version) %>%
#   filter(GroupId %in% c("org.slf4j", "commons-logging", "asm", "junit", "antlr")) %>%
#   ggplot(aes(Release, PageRank, color = GroupId, shape = GroupId)) +
#   geom_line() +
#   geom_point(size = 2) +
#   geom_text(
#     aes(label = ifelse(PageRank > 5, as.character(Version), '')),
#     hjust = 0,
#     vjust = 0,
#     show.legend = FALSE
#   ) +
#   xlab("Release Date") +
#   theme(legend.position = "top") +
#   # scale_color_manual(values = wes_palette(n = 5, name = "GrandBudapest1")) +
#   theme(legend.title = element_blank())

```

```{r}

data$GroupId <- as.character(data$GroupId)
datatmp <- data %>%
  filter(grepl("^commons", GroupId)) %>%
  filter(GroupId %in% c("commons-logging", "commons-io", "commons-codec", "commons-collections", "commons-lang")) %>%
  mutate(factor = PageRank/max)


# Page Rank
datatmp %>%
  ggplot(aes(Release, factor, color = GroupId, shape = GroupId)) +
  geom_line() +
  geom_point(size = 2) +
  geom_text(aes(label=ifelse(factor>.1,as.character(Version),'')),hjust=0,vjust=0,show.legend = FALSE) +
  xlab("Release Date") +
  theme(legend.position="right") +
  scale_fill_brewer(palette="Dark2") +
  ylab("PageRank Factor")  
  #+
  #scale_fill_manual("legend_title")
```


# Maven Central Clustering

```{r}

# Union Find
data$UnionFind <- as.factor(data$UnionFind)
summary(data$UnionFind)


datatmp <- data %>% group_by(UnionFind) %>%
  summarise(no_artifacts = length(UnionFind))

datatmp$no_rows <- as.factor(datatmp$no_artifacts)
datatmp <- datatmp %>% group_by(no_artifacts) %>%
  summarise(clusters = length(no_artifacts)) %>%
  arrange(desc(no_artifacts))

print(xtable(datatmp, type = "latex"), file = "TexTables/table_union_find.tex")

```
